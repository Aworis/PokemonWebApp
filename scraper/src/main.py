from config_loader import ConfigLoader
from scraper_manager import ScraperManager
from sitemap_parser import SitemapParser
from utils.logging_config import setup_logging

# TODO: logging ordner 채ndern auf scraping logger
setup_logging()

# Initialisierung der zentralen Scraper-Komponente
scraper_manager = ScraperManager()
session = scraper_manager.session

# Laden der Sitemap-Konfiguration aus YAML-Datei
config_loader = ConfigLoader()
sitemaps = config_loader.load_sitemap_urls()

# Extrahieren aller URLs aus den jeweiligen Sitemaps
for key in sitemaps:
    sitemap_url = sitemaps.get(f"{key}")

    sitemap_parser = SitemapParser(sitemap_url)
    sitemap_parser.load()

    urls = sitemap_parser.get_matching_urls(rf"{key}/[\w-]+\.php$")

    #TODO: Sp채ter wieder entfernen.
    #Zum Testen: Nur die ersten paar Eintr채ge behalten.
    urls = urls[:4]

    scraper_manager.register_scraper(key, urls)

# Ausf체hrung aller registrierten Scraper
scraper_manager.run_all()